{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80992911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edf5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac12011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets:\n",
    "    def loader_cifar100(batch_size=64, num_workers=2):\n",
    "        transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),  \n",
    "        ])\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "        testset  = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        testloader  = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        print(f\"[CIFAR100] Treino: {len(trainset)} | Teste: {len(testset)}\")\n",
    "        return trainset, testset, trainloader, testloader\n",
    "\n",
    "    def loader_food101(batch_size=64, num_workers=2):\n",
    "        transform = T.Compose([\n",
    "            T.Resize((224, 224)),  \n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.545, 0.436, 0.342), (0.294, 0.275, 0.281))\n",
    "        ])\n",
    "\n",
    "        trainset = torchvision.datasets.Food101(root=\"./data\", split=\"train\", download=True, transform=transform)\n",
    "        testset  = torchvision.datasets.Food101(root=\"./data\", split=\"test\", download=True, transform=transform)\n",
    "\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        testloader  = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        print(f\"[Food-101] Treino: {len(trainset)} | Teste: {len(testset)}\")\n",
    "        return trainset, testset, trainloader, testloader\n",
    "\n",
    "    def loader_caltech256(batch_size=64, num_workers=2):\n",
    "        transform = T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        dataset = torchvision.datasets.Caltech256(root=\"./data\", download=True, transform=transform)\n",
    "\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        testloader  = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        print(f\"[Caltech-256] Treino: {len(trainset)} | Teste: {len(testset)}\")\n",
    "        return trainset, testset, trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-100\n",
    "cifar_train, cifar_test, cifar_trainloader, cifar_testloader = Datasets.loader_cifar100()\n",
    "\n",
    "# Food-101\n",
    "food_train, food_test, food_trainloader, food_testloader = Datasets.loader_food101()\n",
    "\n",
    "# Caltech-256\n",
    "caltech_train, caltech_test, caltech_trainloader, caltech_testloader = Datasets.loader_caltech256()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8a935",
   "metadata": {},
   "source": [
    "Algoritmo escolhido - VGG: compare sua variante com vgg11, vgg13, vgg16, vgg19 (com ou sem _bn).\n",
    "\n",
    "protocolo de treino - (√©pocas, otimizador, LR schedule, augmentation)\n",
    "\n",
    "Usar VGG como feature extractor e Transformer como classificador:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8bf375",
   "metadata": {},
   "source": [
    "Blocos de convolu√ß√£o 3√ó3 empilhados (geralmente 2 ou 3 convs antes de um max pooling).\n",
    "\n",
    "Camadas totalmente conectadas no final (ou um classificador simples).\n",
    "\n",
    "Arquitetura ‚Äúprofunda e simples‚Äù (sem atalhos ou estruturas complexas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_Autoral(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace=True)\n",
      "    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG_Autoral(nn.Module):\n",
    "    def __init__(self, num_classes=1000, dropout=0.5):\n",
    "        super(VGG_Autoral, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG_Autoral(num_classes=1000)\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134a1f5",
   "metadata": {},
   "source": [
    "N√∫mero de filtros pr√≥prio (ex.: 32 ‚Üí 64 ‚Üí 128 ‚Üí 256 ‚Üí 256)\n",
    "\n",
    "Batch Normalization ap√≥s cada conv\n",
    "\n",
    "Dropout ajustado no classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c79ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "\n",
      "üöÄ Treinando VGG_Autoral...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ Treinando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    173\u001b[39m     model.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     train_accs, val_accs = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     results[name] = (train_accs, val_accs)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# üîπ 7. Gr√°fico de acur√°cia\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, name, epochs)\u001b[39m\n\u001b[32m    115\u001b[39m images, labels = images.to(device), labels.to(device).long()  \u001b[38;5;66;03m# <-- garante tipo correto\u001b[39;00m\n\u001b[32m    116\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m    119\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mVGG_Autoral.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classifier(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bruno\\ICA\\Inteligencia_computacional_aplicada\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # mostra erros exatos da GPU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import Food101\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 1. Fixar semente para reprodutibilidade\n",
    "# ================================================================\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 2. Pr√©-processamento e augmentations\n",
    "# ================================================================\n",
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 3. Dataset e DataLoader (Food-101)\n",
    "# ================================================================\n",
    "food_train = Food101(root=\"./data\", split=\"train\", download=True, transform=train_transform)\n",
    "food_test = Food101(root=\"./data\", split=\"test\", download=True, transform=test_transform)\n",
    "\n",
    "# Criar uma valida√ß√£o (20%) a partir do treino\n",
    "train_size = int(0.8 * len(food_train))\n",
    "val_size = len(food_train) - train_size\n",
    "train_dataset, val_dataset = random_split(food_train, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(food_test, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 4. Modelo VGG_Autoral\n",
    "# ================================================================\n",
    "class VGG_Autoral(nn.Module):\n",
    "    def __init__(self, num_classes=101, dropout=0.5):  # <-- corrigido: 101 classes\n",
    "        super(VGG_Autoral, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 4096), nn.ReLU(True), nn.Dropout(dropout),\n",
    "            nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(dropout),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 5. Fun√ß√£o de treino/valida√ß√£o\n",
    "# ================================================================\n",
    "def train_model(model, name, epochs=50):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    best_val, patience, patience_counter = 0, 7, 0\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Treino ---\n",
    "        model.train()\n",
    "        total, correct = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).long()  # <-- garante tipo correto\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # --- Valida√ß√£o ---\n",
    "        model.eval()\n",
    "        total, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).long()\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_accs.append(val_acc)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"[{name}] √âpoca {epoch+1}/{epochs} | Treino: {train_acc:.3f} | Val: {val_acc:.3f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"{name}_best.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚èπÔ∏è Early stopping em {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return train_accs, val_accs\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 6. Compara√ß√£o entre variantes\n",
    "# ================================================================\n",
    "model_names = {\n",
    "    \"VGG_Autoral\": VGG_Autoral(num_classes=101),\n",
    "    \"VGG11_BN\": models.vgg11_bn(num_classes=101),\n",
    "    \"VGG13_BN\": models.vgg13_bn(num_classes=101),\n",
    "    \"VGG16_BN\": models.vgg16_bn(num_classes=101),\n",
    "    \"VGG19_BN\": models.vgg19_bn(num_classes=101),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in model_names.items():\n",
    "    print(f\"\\nüöÄ Treinando {name}...\")\n",
    "    model.to(device)\n",
    "    train_accs, val_accs = train_model(model, name, epochs=50)\n",
    "    results[name] = (train_accs, val_accs)\n",
    "\n",
    "# ================================================================\n",
    "# üîπ 7. Gr√°fico de acur√°cia\n",
    "# ================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, (train_accs, val_accs) in results.items():\n",
    "    plt.plot(val_accs, label=f\"{name} (val)\")\n",
    "plt.title(\"Compara√ß√£o de acur√°cia de valida√ß√£o - Fam√≠lia VGG (Food-101)\")\n",
    "plt.xlabel(\"√âpocas\")\n",
    "plt.ylabel(\"Acur√°cia\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395bc01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA dispon√≠vel: True\n",
      "Vers√£o PyTorch: 2.6.0+cu124\n",
      "Vers√£o CUDA: 12.4\n",
      "Placa detectada: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA dispon√≠vel:\", torch.cuda.is_available())\n",
    "print(\"Vers√£o PyTorch:\", torch.__version__)\n",
    "print(\"Vers√£o CUDA:\", torch.version.cuda)\n",
    "print(\"Placa detectada:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Configura√ß√£o de device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando device: {device}\")\n",
    "\n",
    "# Definir seed para reprodutibilidade\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Carregar datasets\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CARREGANDO DATASETS\")\n",
    "print(\"=\"*50)\n",
    "train_loaders, test_loaders = load_datasets(seed=42)\n",
    "\n",
    "# Ajustar n√∫mero de classes para cada dataset\n",
    "num_classes_por_dataset = {\n",
    "    \"Food-101\": 101,\n",
    "    \"Tiny-ImageNet\": 200,\n",
    "    \"CIFAR-100\": 100\n",
    "}\n",
    "\n",
    "# Inicializar modelos para cada dataset\n",
    "def criar_modelos_para_dataset(num_classes):\n",
    "    \"\"\"Cria inst√¢ncias dos modelos VGG com n√∫mero correto de classes\"\"\"\n",
    "    vgg11 = models.vgg11(weights=None)\n",
    "    vgg11.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    \n",
    "    vgg13 = models.vgg13(weights=None)\n",
    "    vgg13.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    \n",
    "    vgg16 = models.vgg16(weights=None)\n",
    "    vgg16.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    \n",
    "    vgg19 = models.vgg19(weights=None)\n",
    "    vgg19.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    \n",
    "    vgg_autoral = VGG_Autoral(num_classes=num_classes)\n",
    "    \n",
    "    return {\n",
    "        \"VGG_Autoral\": vgg_autoral,\n",
    "        \"VGG11\": vgg11,\n",
    "        \"VGG13\": vgg13,\n",
    "        \"VGG16\": vgg16,\n",
    "        \"VGG19\": vgg19\n",
    "    }\n",
    "\n",
    "# Dicion√°rio para armazenar todos os resultados\n",
    "resultados_completos = {}\n",
    "modelos_treinados = {}\n",
    "\n",
    "# Loop principal: treinar todos os modelos em todos os datasets\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INICIANDO TREINAMENTO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for dataset_name in [\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"DATASET: {dataset_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    num_classes = num_classes_por_dataset[dataset_name]\n",
    "    modelos = criar_modelos_para_dataset(num_classes)\n",
    "    \n",
    "    train_loader = train_loaders[dataset_name]\n",
    "    test_loader = test_loaders[dataset_name]\n",
    "    \n",
    "    # Criar validation loader (20% do test set)\n",
    "    test_dataset = test_loader.dataset\n",
    "    val_size = int(0.2 * len(test_dataset))\n",
    "    test_size = len(test_dataset) - val_size\n",
    "    val_dataset, _ = torch.utils.data.random_split(\n",
    "        test_dataset, \n",
    "        [val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    \n",
    "    modelos_treinados[dataset_name] = {}\n",
    "    \n",
    "    for nome_modelo, modelo in modelos.items():\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"Treinando {nome_modelo} em {dataset_name}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        # Treinar modelo\n",
    "        modelo_treinado, historico = train_model(\n",
    "            modelo, \n",
    "            train_loader, \n",
    "            val_loader, \n",
    "            device=device,\n",
    "            optimizer_name=\"AdamW\",\n",
    "            lr=0.001,\n",
    "            scheduler_type=\"cosine\",\n",
    "            epochs=50,\n",
    "            patience=10\n",
    "        )\n",
    "        \n",
    "        # Salvar modelo treinado\n",
    "        modelos_treinados[dataset_name][nome_modelo] = modelo_treinado\n",
    "        \n",
    "        # Avaliar no test set\n",
    "        print(f\"\\nAvaliando {nome_modelo} no test set...\")\n",
    "        metricas = Metrics.evaluate_model(modelo_treinado, test_loader, device)\n",
    "        \n",
    "        # Obter complexidade e desempenho\n",
    "        complexidade = Metrics.get_model_complexity(modelo_treinado)\n",
    "        desempenho = Metrics.benchmark_model(modelo_treinado, device)\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "        resultados_completos[chave] = {\n",
    "            **metricas,\n",
    "            **complexidade,\n",
    "            **desempenho,\n",
    "            \"historico\": historico\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nResultados {nome_modelo}:\")\n",
    "        print(f\"  Acur√°cia: {metricas['Acur√°cia']:.4f}\")\n",
    "        print(f\"  F1-Score: {metricas['F1']:.4f}\")\n",
    "        print(f\"  NLL: {metricas['NLL']:.4f}\")\n",
    "        print(f\"  ECE: {metricas['ECE']:.4f}\")\n",
    "        print(f\"  Par√¢metros: {complexidade['Par√¢metros']/1e6:.2f}M\")\n",
    "        print(f\"  Lat√™ncia: {desempenho['Lat√™ncia (s)']:.4f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TREINAMENTO CONCLU√çDO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# GERAR GR√ÅFICOS E AN√ÅLISES\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GERANDO GR√ÅFICOS E AN√ÅLISES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Compara√ß√£o de Acur√°cia por Dataset\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, dataset_name in enumerate([\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"], 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    nomes = []\n",
    "    acuracias = []\n",
    "    for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "        chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "        nomes.append(nome_modelo)\n",
    "        acuracias.append(resultados_completos[chave][\"Acur√°cia\"])\n",
    "    \n",
    "    cores = ['#d62828', '#f77f00', '#fcbf49', '#06d6a0', '#118ab2']\n",
    "    plt.bar(nomes, acuracias, color=cores)\n",
    "    plt.title(f\"{dataset_name}\", fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(\"Acur√°cia\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacao_acuracia.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Compara√ß√£o de Complexidade (Par√¢metros vs FLOPs)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for dataset_name in [\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]:\n",
    "    params = []\n",
    "    flops = []\n",
    "    nomes = []\n",
    "    for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "        chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "        params.append(resultados_completos[chave][\"Par√¢metros\"] / 1e6)\n",
    "        flops.append(resultados_completos[chave][\"FLOPs\"] / 1e9)\n",
    "        nomes.append(nome_modelo)\n",
    "    \n",
    "    plt.scatter(params, flops, label=dataset_name, s=100, alpha=0.7)\n",
    "    \n",
    "    for i, nome in enumerate(nomes):\n",
    "        if dataset_name == \"Food-101\":\n",
    "            plt.annotate(nome, (params[i], flops[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.xlabel(\"Par√¢metros (Milh√µes)\")\n",
    "plt.ylabel(\"FLOPs (GFLOPs)\")\n",
    "plt.title(\"Complexidade dos Modelos\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('complexidade_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Compara√ß√£o de M√©tricas (Precision, Recall, F1)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "metricas_plot = [\"Precis√£o\", \"Recall\", \"F1\"]\n",
    "\n",
    "for idx, metrica in enumerate(metricas_plot):\n",
    "    ax = axes[idx]\n",
    "    x = np.arange(5)\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, dataset_name in enumerate([\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]):\n",
    "        valores = []\n",
    "        for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "            chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "            valores.append(resultados_completos[chave][metrica])\n",
    "        \n",
    "        ax.bar(x + i*width, valores, width, label=dataset_name)\n",
    "    \n",
    "    ax.set_xlabel(\"Modelo\")\n",
    "    ax.set_ylabel(metrica)\n",
    "    ax.set_title(f\"Compara√ß√£o de {metrica}\")\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels([\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacao_metricas.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 4. Calibra√ß√£o (NLL e ECE)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, metrica in enumerate([\"NLL\", \"ECE\"]):\n",
    "    ax = axes[idx]\n",
    "    x = np.arange(5)\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, dataset_name in enumerate([\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]):\n",
    "        valores = []\n",
    "        for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "            chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "            valores.append(resultados_completos[chave][metrica])\n",
    "        \n",
    "        ax.bar(x + i*width, valores, width, label=dataset_name)\n",
    "    \n",
    "    ax.set_xlabel(\"Modelo\")\n",
    "    ax.set_ylabel(metrica)\n",
    "    ax.set_title(f\"Calibra√ß√£o - {metrica}\")\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels([\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibracao_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Lat√™ncia de Infer√™ncia\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(5)\n",
    "width = 0.25\n",
    "\n",
    "for i, dataset_name in enumerate([\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]):\n",
    "    latencias = []\n",
    "    for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "        chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "        latencias.append(resultados_completos[chave][\"Lat√™ncia (s)\"] * 1000)  # Converter para ms\n",
    "    \n",
    "    plt.bar(x + i*width, latencias, width, label=dataset_name)\n",
    "\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylabel(\"Lat√™ncia (ms)\")\n",
    "plt.title(\"Lat√™ncia de Infer√™ncia\")\n",
    "plt.xticks(x + width, [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('latencia_inferencia.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6. Curvas de Aprendizado (Loss e Acur√°cia)\n",
    "for dataset_name in [\"Food-101\", \"Tiny-ImageNet\", \"CIFAR-100\"]:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for nome_modelo in [\"VGG_Autoral\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n",
    "        chave = f\"{dataset_name}_{nome_modelo}\"\n",
    "        hist = resultados_completos[chave][\"historico\"]\n",
    "        \n",
    "        # Loss\n",
    "        axes[0].plot(hist[\"train_loss\"], label=f\"{nome_modelo} (Train)\", linestyle='--', alpha=0.7)\n",
    "        axes[0].plot(hist[\"val_loss\"], label=f\"{nome_modelo} (Val)\")\n",
    "        \n",
    "        # Acur√°cia\n",
    "        axes[1].plot(hist[\"train_acc\"], label=f\"{nome_modelo} (Train)\", linestyle='--', alpha=0.7)\n",
    "        axes[1].plot(hist[\"val_acc\"], label=f\"{nome_modelo} (Val)\")\n",
    "    \n",
    "    axes[0].set_xlabel(\"√âpoca\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(f\"{dataset_name} - Curva de Loss\")\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].set_xlabel(\"√âpoca\")\n",
    "    axes[1].set_ylabel(\"Acur√°cia\")\n",
    "    axes[1].set_title(f\"{dataset_name} - Curva de Acur√°cia\")\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'curvas_aprendizado_{dataset_name.replace(\"-\", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 7. Tabela Resumo\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABELA RESUMO DE RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
