{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad1d2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7aa2faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from ucimlrepo) (2.3.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from ucimlrepo) (2025.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/brunolinux/ICA/Inteligencia_computacional_aplicada/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf361a",
   "metadata": {},
   "source": [
    "Implementação Perceptron Clássico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "25eaf207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_breast_cancer():\n",
    "        breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "        X = breast_cancer_wisconsin_diagnostic.data.features.to_numpy()\n",
    "        y = breast_cancer_wisconsin_diagnostic.data.targets.iloc[:, 0].to_numpy()\n",
    "\n",
    "        y = np.where(y == \"M\", 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1317e16",
   "metadata": {},
   "source": [
    "Pre-Processamento dos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3d9831d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold(X, y, n_splits=5):\n",
    "    classes = np.unique(y)\n",
    "    idx_splits = [[] for _ in range(n_splits)]\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_idx = np.where(y == cls)[0]\n",
    "        np.random.shuffle(cls_idx)\n",
    "        cls_splits = np.array_split(cls_idx, n_splits)\n",
    "        for i in range(n_splits):\n",
    "            idx_splits[i].extend(cls_splits[i])\n",
    "\n",
    "    folds = []\n",
    "    for i in range(n_splits):\n",
    "        test_idx = np.array(idx_splits[i])\n",
    "        train_idx = np.array([idx for j, fold in enumerate(idx_splits) if j != i for idx in fold])\n",
    "        folds.append((train_idx, test_idx))\n",
    "\n",
    "    return folds\n",
    "\n",
    "def z_score(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    std[std == 0] = 1\n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    return X_train_scaled, X_test_scaled        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd4ca3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix_manual(y_true, y_pred, classes=[0, 1], normalize=False, title=\"Matriz de Confusão\"):\n",
    "    \"\"\"\n",
    "    Plota a matriz de confusão usando matplotlib, sem sklearn.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - y_true: rótulos verdadeiros\n",
    "    - y_pred: rótulos preditos\n",
    "    - classes: lista de classes\n",
    "    - normalize: se True, mostra proporção\n",
    "    - title: título do gráfico\n",
    "    \"\"\"\n",
    "    n_classes = len(classes)\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    class_to_index = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "    # Preencher a matriz\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        i = class_to_index[true]\n",
    "        j = class_to_index[pred]\n",
    "        cm[i, j] += 1\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plotar com matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # Mostrar os números dentro das células\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.set_xlabel(\"Predito\")\n",
    "    ax.set_ylabel(\"Verdadeiro\")\n",
    "    ax.set_xticks(np.arange(n_classes))\n",
    "    ax.set_yticks(np.arange(n_classes))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2256e4",
   "metadata": {},
   "source": [
    "Implementação Perceptron Clássico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "12909aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, epochs=100, eta=0.1):\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, d = X.shape\n",
    "        self.w = np.zeros(d + 1)  # inclui bias\n",
    "\n",
    "        # Converter labels para -1 e 1\n",
    "        y_binary = np.where(y == 0, -1, 1)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            errors = 0\n",
    "            indices = np.arange(n)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            for i in indices:\n",
    "                x_i = np.append(X[i], 1) \n",
    "                if y_binary[i] * np.dot(self.w, x_i) <= 0:\n",
    "                    self.w += self.eta * y_binary[i] * x_i\n",
    "                    errors += 1\n",
    "\n",
    "            if errors == 0:\n",
    "                print(f\"Convergência na época {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X_bias = np.c_[X, np.ones(X.shape[0])]\n",
    "        return X_bias @ self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.sign(self.decision_function(X))\n",
    "        return np.where(pred == -1, 0, 1)  # volta para 0/1\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62b818e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_f1(y_true, y_pred, n_classes=None):\n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(np.concatenate([y_true, y_pred])))\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        tp = np.sum((y_true == i) & (y_pred == i))\n",
    "        fp = np.sum((y_true != i) & (y_pred == i))\n",
    "        fn = np.sum((y_true == i) & (y_pred != i))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2c8fb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergência na época 146\n",
      "Convergência na época 446\n",
      "epochs=500, lr=0.001 -> Acurácia TESTE: 0.9579 ± 0.0128 | Macro-F1: 0.9552 ± 0.0133\n",
      "Convergência na época 100\n",
      "Convergência na época 350\n",
      "epochs=500, lr=0.010 -> Acurácia TESTE: 0.9596 ± 0.0044 | Macro-F1: 0.9569 ± 0.0044\n",
      "Convergência na época 108\n",
      "Convergência na época 381\n",
      "epochs=500, lr=0.100 -> Acurácia TESTE: 0.9596 ± 0.0069 | Macro-F1: 0.9571 ± 0.0072\n",
      "Convergência na época 78\n",
      "Convergência na época 280\n",
      "epochs=1000, lr=0.001 -> Acurácia TESTE: 0.9562 ± 0.0144 | Macro-F1: 0.9534 ± 0.0150\n",
      "Convergência na época 98\n",
      "Convergência na época 248\n",
      "epochs=1000, lr=0.010 -> Acurácia TESTE: 0.9596 ± 0.0117 | Macro-F1: 0.9570 ± 0.0123\n",
      "Convergência na época 117\n",
      "Convergência na época 320\n",
      "epochs=1000, lr=0.100 -> Acurácia TESTE: 0.9596 ± 0.0069 | Macro-F1: 0.9570 ± 0.0071\n",
      "\n",
      "Melhor configuração: epochs=1000, lr=0.01 -> Acurácia 0.9596 ± 0.0117 | Macro-F1 0.9570 ± 0.0123\n",
      "Convergência na época 408\n",
      "Matriz de Confusão:\n",
      "Pred→\t0\t1\n",
      "Verdadeiro 0:\t67\t4\n",
      "Verdadeiro 1:\t1\t41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_stratified_cross_validation():\n",
    "    \n",
    "    X, y = loader_breast_cancer()\n",
    "    \n",
    "    param_grid = {\n",
    "        \"epochs\": [500, 1000],\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    k_folds = 5\n",
    "    best_result = None\n",
    "    results = []\n",
    "    \n",
    "    folds = stratified_kfold(X, y, n_splits=k_folds)\n",
    "    \n",
    "    for epochs in param_grid[\"epochs\"]:\n",
    "        for learning_rate in param_grid[\"learning_rate\"]:\n",
    "            \n",
    "            accuracies_test = []\n",
    "            f1_scores = []\n",
    "            \n",
    "            for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                X_train_scaled, X_test_scaled = z_score(X_train, X_test)\n",
    "\n",
    "                model = Perceptron(epochs=epochs, eta=learning_rate)\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                test_accuracy = model.accuracy(X_test_scaled, y_test)\n",
    "                accuracies_test.append(test_accuracy)\n",
    "\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                f1 = compute_macro_f1(y_test, y_pred)\n",
    "                f1_scores.append(f1)\n",
    "            \n",
    "            mean_test = np.mean(accuracies_test)\n",
    "            std_test = np.std(accuracies_test)\n",
    "            mean_f1 = np.mean(f1_scores)\n",
    "            std_f1 = np.std(f1_scores)\n",
    "            \n",
    "            print(f\"epochs={epochs}, lr={learning_rate:.3f} -> \"\n",
    "                  f\"Acurácia TESTE: {mean_test:.4f} ± {std_test:.4f} | \"\n",
    "                  f\"Macro-F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "            \n",
    "            results.append(((epochs, learning_rate), mean_test, std_test, mean_f1, std_f1))\n",
    "            \n",
    "            if best_result is None or mean_test > best_result[1]:\n",
    "                best_result = ((epochs, learning_rate), mean_test, std_test, mean_f1, std_f1)\n",
    "    \n",
    "    best_params, best_mean, best_std, best_f1, best_f1_std = best_result\n",
    "    print(f\"\\nMelhor configuração: epochs={best_params[0]}, lr={best_params[1]} \"\n",
    "          f\"-> Acurácia {best_mean:.4f} ± {best_std:.4f} | \"\n",
    "          f\"Macro-F1 {best_f1:.4f} ± {best_f1_std:.4f}\")\n",
    "\n",
    "    # --- Matriz de confusão usando o último fold do melhor parâmetro ---\n",
    "    # Treinar novamente no último fold do melhor conjunto de parâmetros\n",
    "    last_train_idx, last_test_idx = folds[-1]\n",
    "    X_train, X_test = X[last_train_idx], X[last_test_idx]\n",
    "    y_train, y_test = y[last_train_idx], y[last_test_idx]\n",
    "    X_train_scaled, X_test_scaled = z_score(X_train, X_test)\n",
    "\n",
    "    best_model = Perceptron(epochs=best_params[0], eta=best_params[1])\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Chamar a matriz de confusão manual\n",
    "    plot_confusion_matrix_manual(y_test, y_pred, classes=[0, 1], normalize=False)\n",
    "\n",
    "    return best_result\n",
    "\n",
    "# --- Execução ---\n",
    "if __name__ == \"__main__\":\n",
    "    best_params = run_stratified_cross_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
